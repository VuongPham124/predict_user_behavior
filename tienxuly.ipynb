{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2548c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import emoji\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d71e49b",
   "metadata": {},
   "source": [
    "# Tiền xử lý tạo tập dữ liệu cơ bản với các đặc trưng thống kê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06e13085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thời gian xử lý: 0.39 giây\n",
      "Số dòng: 18064\n",
      "Số cột: 25\n"
     ]
    }
   ],
   "source": [
    "def preprocess_dataframe(df):\n",
    "    # Xử lý nội dung văn bản\n",
    "    df['has_emoji'] = df['text'].fillna('').apply(lambda x: int(any(c in emoji.EMOJI_DATA for c in x)))\n",
    "    df['has_caps_words'] = df['text'].str.contains(r'\\b[A-Z]{2,}\\b', na=False).astype(int)\n",
    "\n",
    "    # Xử lý media\n",
    "    df['media_type_list'] = df['media_type'].fillna('').str.lower().apply(lambda x: [m.strip() for m in x.split(',') if m.strip()])\n",
    "    for media_type in ['photo', 'video', 'animated_gif']:\n",
    "        df[f'has_{media_type}'] = df['media_type_list'].apply(lambda x: int(media_type in x))\n",
    "    df['media_count'] = df['media_type_list'].apply(len)\n",
    "\n",
    "    # Trích xuất thông tin thời gian\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')\n",
    "    df['hour'] = df['created_at'].dt.hour\n",
    "    df['day_of_week'] = df['created_at'].dt.dayofweek\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "    df['month'] = df['created_at'].dt.month\n",
    "\n",
    "    # Thông tin người dùng\n",
    "    df['is_influencer'] = (df['user_followers_count'] > 100000).astype(int)\n",
    "\n",
    "    # Ép kiểu cột boolean\n",
    "    for col in ['is_repost', 'is_reply', 'is_quote']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(int)\n",
    "\n",
    "    # Tạo nhãn đầu ra \n",
    "    like_bins   = [-1, 0, 52, 2443, 9389, float('inf')]\n",
    "    reply_bins  = [-1, 0, 2, 49, 228, float('inf')]\n",
    "    quote_bins  = [-1, 0, 21, 107, 1151, float('inf')]\n",
    "    repost_bins = [-1, 0, 91, 1087, 3823, float('inf')]\n",
    "\n",
    "    labels = ['None', 'Very Low', 'Low', 'Medium', 'High']\n",
    "\n",
    "    df['Like_Level']   = pd.cut(df['like_count'],   bins=like_bins,   labels=labels, include_lowest=True)\n",
    "    df['Reply_Level']  = pd.cut(df['reply_count'],  bins=reply_bins,  labels=labels, include_lowest=True)\n",
    "    df['Quote_Level']  = pd.cut(df['quote_count'],  bins=quote_bins,  labels=labels, include_lowest=True)\n",
    "    df['Repost_Level'] = pd.cut(df['repost_count'], bins=repost_bins, labels=labels, include_lowest=True)\n",
    "\n",
    "    # Xóa cột\n",
    "    drop_cols = [\n",
    "        'created_at', 'media_type', 'media_path', 'media_type_list',\n",
    "        'post_id', 'text', 'like_count', 'repost_count',\n",
    "        'reply_count', 'quote_count', 'cleaned_text'\n",
    "    ]\n",
    "    df.drop(columns=[col for col in drop_cols if col in df.columns], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "\n",
    "    df = pd.read_csv('data.csv')\n",
    "    df_processed = preprocess_dataframe(df)\n",
    "    df_processed.to_csv('data_base.csv', index=False, encoding='utf-8')\n",
    "\n",
    "    print(f'Thời gian xử lý: {time.time() - start_time:.2f} giây')\n",
    "    print(f'Số dòng: {df_processed.shape[0]}')\n",
    "    print(f'Số cột: {df_processed.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f389063",
   "metadata": {},
   "source": [
    "# Tiền xử lý tạo tập dữ liệu mở rộng bao gồm các đặc trưng thống kê và các đặc trưng trích xuất từ nội dung post (sentiment, CTA, clickbait, NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1281e167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at joeddav/xlm-roberta-large-xnli were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Tính điểm cảm xúc: 100%|██████████| 565/565 [1:43:35<00:00, 11.00s/it]  \n",
      "Phân loại CTA / Clickbait: 100%|██████████| 565/565 [36:14<00:00,  3.85s/it]\n",
      "Phát hiện thực thể: 100%|██████████| 565/565 [45:05<00:00,  4.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thời gian xử lý: 11097.31 giây\n",
      "Số dòng: 18064\n",
      "Số cột: 31\n"
     ]
    }
   ],
   "source": [
    "# Làm sạch text\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    \n",
    "    text = str(text).strip()\n",
    "\n",
    "    # Xóa \"RT\" và người dùng repost\n",
    "    text = re.sub(r'^RT @\\w+:\\s*|\\bRT\\b', '', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Thay URL bằng [URL]\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '[URL]', text)\n",
    "\n",
    "    # Loại bỏ @ nhưng giữ tên người dùng\n",
    "    text = re.sub(r'@(\\w+)', r'\\1', text)\n",
    "\n",
    "    # Loại bỏ # nhưng giữ tên hashtag\n",
    "    text = re.sub(r'#(\\w+)', r'\\1', text)\n",
    "\n",
    "    # Xóa các thực thể HTML (như &amp;)\n",
    "    text = re.sub(r'&[a-zA-Z0-9]+;', ' ', text)\n",
    "\n",
    "    # Chuyển emoji sang dạng text (:heart:, :fire:)\n",
    "    text = emoji.demojize(text, delimiters=(':', ':'))\n",
    "\n",
    "    # Thêm khoảng trắng giữa emoji liền nhau\n",
    "    text = re.sub(r'(:[^:\\s]+:)(?=:)', r'\\1 ', text)\n",
    "\n",
    "    # Loại dấu : và _ (để dễ xử lý văn bản sau)\n",
    "    text = re.sub(r'[:_]', ' ', text)\n",
    "\n",
    "    # Xóa dấu câu và lặp dấu\n",
    "    text = re.sub(r'[!?.,;]+', ' ', text)\n",
    "\n",
    "    # Xóa ký tự đặc biệt còn lại\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Xóa dòng và chuẩn hóa khoảng trắng\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "# Tải mô hình\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError('Không tìm thấy GPU!')\n",
    "\n",
    "DEVICE = torch.device('cuda')\n",
    "\n",
    "# Mô hình phân tích cảm xúc\n",
    "SENTIMENT_MODEL = 'cardiffnlp/twitter-xlm-roberta-base-sentiment'\n",
    "tokenizer_sent = AutoTokenizer.from_pretrained(SENTIMENT_MODEL)\n",
    "model_sent = AutoModelForSequenceClassification.from_pretrained(SENTIMENT_MODEL).to(DEVICE)\n",
    "\n",
    "# Mô hình phân loại CTA & clickbait\n",
    "cta_classifier = pipeline(\n",
    "    'zero-shot-classification',\n",
    "    model='joeddav/xlm-roberta-large-xnli',\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "# Mô hình nhận diện thực thể\n",
    "ner_pipe = pipeline(\n",
    "    'ner',\n",
    "    model='Davlan/xlm-roberta-base-ner-hrl',\n",
    "    aggregation_strategy='simple',\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "# Hàm chạy mô hình\n",
    "def named_entit(texts, batch_size=32):\n",
    "    flags = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc='Phát hiện thực thể'):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        try:\n",
    "            results = ner_pipe(batch)\n",
    "            flags.extend([int(len(res) > 0) for res in results])\n",
    "        except:\n",
    "            flags.extend([0] * len(batch))\n",
    "    return flags\n",
    "\n",
    "def sentiment_score(texts, batch_size=32):\n",
    "    results = []\n",
    "    model_sent.eval()\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc='Tính điểm cảm xúc'):\n",
    "        batch = [str(t) if t else '' for t in texts[i:i + batch_size]]\n",
    "        inputs = tokenizer_sent(batch, padding=True, truncation=True, max_length=512, return_tensors='pt').to(DEVICE)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model_sent(**inputs).logits\n",
    "            probs = F.softmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "        for prob in probs:\n",
    "            score = prob[2] - prob[0]\n",
    "            results.append(score)\n",
    "    return results\n",
    "\n",
    "def cta_clickbait(texts, threshold=0.5, batch_size=32):\n",
    "    labels = ['contains CTA', 'clickbait']\n",
    "    has_cta_flags = []\n",
    "    is_clickbait_flags = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc='Phân loại CTA / Clickbait'):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        results = cta_classifier(batch, candidate_labels=labels, hypothesis_template='This text is {}.', multi_label=True)\n",
    "\n",
    "        for res in results:\n",
    "            scores = dict(zip(res['labels'], res['scores']))\n",
    "            has_cta_flags.append(int(scores['contains CTA'] >= threshold))\n",
    "            is_clickbait_flags.append(int(scores['clickbait'] >= threshold))\n",
    "    \n",
    "    return has_cta_flags, is_clickbait_flags\n",
    "\n",
    "def preprocess_dataframe(df):\n",
    "    # Làm sạch văn bản\n",
    "    df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "    texts = df['text'].astype(str).tolist()\n",
    "    texts_cleaned = df['cleaned_text'].tolist()\n",
    "\n",
    "    # Đặc trưng từ văn bản\n",
    "    df['has_emoji'] = df['text'].fillna('').apply(lambda x: int(any(c in emoji.EMOJI_DATA for c in x)))\n",
    "    df['has_caps_words'] = df['text'].str.contains(r'\\b[A-Z]{2,}\\b', na=False).astype(int)\n",
    "\n",
    "    # Phân tích media\n",
    "    df['media_path_list'] = df['media_path'].fillna('').apply(lambda x: [p.strip() for p in x.split(',') if p.strip()])\n",
    "    df['media_type_list'] = df['media_type'].fillna('').str.lower().apply(lambda x: [m.strip() for m in x.split(',') if m.strip()])\n",
    "    for media_type in ['photo', 'video', 'animated_gif']:\n",
    "        df[f'has_{media_type}'] = df['media_type_list'].apply(lambda x: int(media_type in x))\n",
    "    df['media_count'] = df['media_type_list'].apply(len)\n",
    "\n",
    "    # Thời gian\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')\n",
    "    df['hour'] = df['created_at'].dt.hour\n",
    "    df['day_of_week'] = df['created_at'].dt.dayofweek\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "    df['month'] = df['created_at'].dt.month\n",
    "\n",
    "    # Người dùng\n",
    "    df['is_influencer'] = (df['user_followers_count'] > 100_000).astype(int)\n",
    "\n",
    "    # Chuyển cột boolean\n",
    "    for col in ['is_repost', 'is_reply', 'is_quote']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(int)\n",
    "\n",
    "    # Phân tích ngữ nghĩa\n",
    "    df['sentiment_score'] = sentiment_score(texts_cleaned)\n",
    "    df['has_cta'], df['is_clickbait'] = cta_clickbait(texts)\n",
    "    df['has_entities'] = named_entit(texts_cleaned)\n",
    "\n",
    "    # Tạo nhãn đầu ra \n",
    "    like_bins   = [-1, 0, 52, 2443, 9389, float('inf')]\n",
    "    reply_bins  = [-1, 0, 2, 49, 228, float('inf')]\n",
    "    quote_bins  = [-1, 0, 21, 107, 1151, float('inf')]\n",
    "    repost_bins = [-1, 0, 91, 1087, 3823, float('inf')]\n",
    "\n",
    "    labels = ['None', 'Very Low', 'Low', 'Medium', 'High']\n",
    "\n",
    "    df['Like_Level']   = pd.cut(df['like_count'],   bins=like_bins,   labels=labels, include_lowest=True)\n",
    "    df['Reply_Level']  = pd.cut(df['reply_count'],  bins=reply_bins,  labels=labels, include_lowest=True)\n",
    "    df['Quote_Level']  = pd.cut(df['quote_count'],  bins=quote_bins,  labels=labels, include_lowest=True)\n",
    "    df['Repost_Level'] = pd.cut(df['repost_count'], bins=repost_bins, labels=labels, include_lowest=True)\n",
    "\n",
    "    # Xoá cột không cần thiết\n",
    "    cols_to_drop = [\n",
    "        'created_at', 'media_type', 'media_path', 'media_type_list',\n",
    "        'post_id', 'text', 'like_count', 'repost_count',\n",
    "        'reply_count', 'quote_count'\n",
    "    ]\n",
    "    df.drop(columns=[c for c in cols_to_drop if c in df.columns], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "\n",
    "    df = pd.read_csv('data.csv')\n",
    "    df_processed = preprocess_dataframe(df)\n",
    "    df_processed.to_csv('data_full.csv', index=False, encoding='utf-8')\n",
    "\n",
    "    print(f'Thời gian xử lý: {time.time() - start_time:.2f} giây')\n",
    "    print(f'Số dòng: {df_processed.shape[0]}')\n",
    "    print(f'Số cột: {df_processed.shape[1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
